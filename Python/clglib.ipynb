{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "['BookID', 'Title', 'CategoryID']\n",
      "[{\"'BookID'\": \"'1'\", \"'Title'\": \"'New Title'\", \"'CategoryID'\": \"'1'\"}, {\"'BookID'\": \"'2'\", \"'Title'\": \"'To Kill a Mockingbird'\", \"'CategoryID'\": \"'1'\"}, {\"'BookID'\": \"'3'\", \"'Title'\": \"'The Great Gatsby'\", \"'CategoryID'\": \"'1'\"}, {\"'BookID'\": \"'4'\", \"'Title'\": \"'1984'\", \"'CategoryID'\": \"'2'\"}, {\"'BookID'\": \"'5'\", \"'Title'\": \"'Brave New World'\", \"'CategoryID'\": \"'2'\"}, {\"'BookID'\": \"'6'\", \"'Title'\": \"'Dune'\", \"'CategoryID'\": \"'2'\"}, {\"'BookID'\": \"'7'\", \"'Title'\": \"'Pride and Prejudice'\", \"'CategoryID'\": \"'3'\"}, {\"'BookID'\": \"'8'\", \"'Title'\": \"'Jane Eyre'\", \"'CategoryID'\": \"'3'\"}, {\"'BookID'\": \"'9'\", \"'Title'\": \"'Wuthering Heights'\", \"'CategoryID'\": \"'3'\"}, {\"'BookID'\": \"'10'\", \"'Title'\": \"'The Hobbit'\", \"'CategoryID'\": \"'4'\"}, {\"'BookID'\": \"'11'\", \"'Title'\": \"'The Lord of the Rings'\", \"'CategoryID'\": \"'4'\"}, {\"'BookID'\": \"'12'\", \"'Title'\": '\\'Harry Potter and the Sorcerer\"\\'s Stone\\'', \"'CategoryID'\": \"'4'\"}, {\"'BookID'\": \"'13'\", \"'Title'\": \"'The Catcher in the Rye'\", \"'CategoryID'\": \"'5'\"}, {\"'BookID'\": \"'14'\", \"'Title'\": \"'Fahrenheit 451'\", \"'CategoryID'\": \"'5'\"}, {\"'BookID'\": \"'15'\", \"'Title'\": \"'The Odyssey'\", \"'CategoryID'\": \"'6'\"}, {\"'BookID'\": \"'16'\", \"'Title'\": \"'The Iliad'\", \"'CategoryID'\": \"'6'\"}, {\"'BookID'\": \"'17'\", \"'Title'\": \"'One Hundred Years of Solitude'\", \"'CategoryID'\": \"'1'\"}, {\"'BookID'\": \"'18'\", \"'Title'\": \"'The Alchemist'\", \"'CategoryID'\": \"'2'\"}, {\"'BookID'\": \"'19'\", \"'Title'\": \"'The Chronicles of Narnia'\", \"'CategoryID'\": \"'4'\"}, {\"'BookID'\": \"'20'\", \"'Title'\": \"'The Shining'\", \"'CategoryID'\": \"'5'\"}, {\"'BookID'\": \"'21'\", \"'Title'\": \"'Jurassic Park'\", \"'CategoryID'\": \"'7'\"}, {\"'BookID'\": \"'22'\", \"'Title'\": \"'The Da Vinci Code'\", \"'CategoryID'\": \"'8'\"}, {\"'BookID'\": \"'23'\", \"'Title'\": \"'The Girl with the Dragon Tattoo'\", \"'CategoryID'\": \"'8'\"}, {\"'BookID'\": \"'24'\", \"'Title'\": \"'The Hunger Games'\", \"'CategoryID'\": \"'9'\"}]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\"\"\"\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/books_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "        print(formatted_line)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_csv_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, encoding=\"utf8\") as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        for row in csv_reader:\n",
    "            formatted_row = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in row) + ']'\n",
    "            print(formatted_row)\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "file_path = 'C:/Users/HUDA/OneDrive/Desktop/books_backup.csv'\n",
    "library_data = load_csv_data(file_path)\n",
    "\n",
    "print(library_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AuthorID', 'AuthorName']\n",
      "['1', 'John Smith']\n",
      "['2', 'Jane Johnson']\n",
      "['3', 'Robert Williams']\n",
      "['4', 'Emily Davis']\n",
      "['5', 'Michael Brown']\n",
      "['6', 'Amanda Jones']\n",
      "['7', 'William Wilson']\n",
      "['8', 'Olivia Moore']\n",
      "['9', 'Daniel Taylor']\n",
      "['10', 'Sophia White']\n",
      "['11', 'Christopher Anderson']\n",
      "['12', 'Mia Garcia']\n",
      "['13', 'Matthew Martinez']\n",
      "['14', 'Emma Robinson']\n",
      "['15', 'Andrew Lee']\n",
      "['16', 'Isabella Taylor']\n",
      "['17', 'James Davis']\n",
      "['18', 'Sophie Brown']\n",
      "['19', 'Joshua Wilson']\n",
      "['20', 'Ella Martinez']\n",
      "['21', 'David Thompson']\n",
      "['22', 'Anna Miller']\n",
      "['23', 'Brian Harris']\n",
      "['24', 'Lily Turner']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/authors_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "       formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "       print(formatted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BorrowID', 'BookID', 'StudentID', 'BorrowDate', 'ReturnDate']\n",
      "['1', '1', '1', '2023-01-01', '2023-01-15']\n",
      "['2', '2', '2', '2023-02-01', '2023-02-15']\n",
      "['3', '3', '3', '2023-03-01', '2023-03-15']\n",
      "['4', '4', '4', '2023-04-01', '2023-04-15']\n",
      "['5', '5', '5', '2023-05-01', '2023-05-15']\n",
      "['6', '6', '6', '2023-06-01', '2023-06-15']\n",
      "['7', '7', '7', '2023-07-01', '2023-07-15']\n",
      "['8', '8', '8', '2023-08-01', '2023-08-15']\n",
      "['9', '9', '9', '2023-09-01', '2023-09-15']\n",
      "['10', '10', '10', '2023-10-01', '2023-10-15']\n",
      "['11', '11', '11', '2023-11-01', '2023-11-15']\n",
      "['12', '12', '12', '2023-12-01', '2023-12-15']\n",
      "['13', '13', '13', '2024-01-01', '2024-01-15']\n",
      "['14', '14', '14', '2024-02-01', '2024-02-15']\n",
      "['15', '15', '15', '2024-03-01', '2024-03-15']\n",
      "['16', '16', '16', '2024-04-01', '2024-04-15']\n",
      "['17', '17', '17', '2024-05-01', '2024-05-15']\n",
      "['18', '18', '18', '2024-06-01', '2024-06-15']\n",
      "['19', '19', '19', '2024-07-01', '2024-07-15']\n",
      "['20', '20', '20', '2024-08-01', '2024-08-15']\n",
      "['21', '21', '21', '2024-09-01', '2024-09-15']\n",
      "['22', '22', '22', '2024-10-01', '2024-10-15']\n",
      "['23', '23', '23', '2024-11-01', '2024-11-15']\n",
      "['24', '24', '24', '2024-12-01', '2024-12-15']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/borrowedbooks_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "       formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "       print(formatted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CategoryID', 'CategoryName']\n",
      "['1', 'Fiction']\n",
      "['2', 'Mystery']\n",
      "['3', 'Romance']\n",
      "['4', 'Science Fiction']\n",
      "['5', 'Horror']\n",
      "['6', 'Fantasy']\n",
      "['7', 'Adventure']\n",
      "['8', 'Thriller']\n",
      "['9', 'Historical Fiction']\n",
      "['10', 'Biography']\n",
      "['11', 'Non-Fiction']\n",
      "['12', 'Self-Help']\n",
      "['13', 'Children\"'s Books']\n",
      "['14', 'Young Adult']\n",
      "['15', 'Poetry']\n",
      "['16', 'Classic']\n",
      "['17', 'Crime']\n",
      "['18', 'Humor']\n",
      "['19', 'Travel']\n",
      "['20', 'Science']\n",
      "['21', 'Philosophy']\n",
      "['22', 'History']\n",
      "['23', 'Art']\n",
      "['24', 'Cooking']\n",
      "['25', 'Sports']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/categories_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "        print(formatted_line)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['StudentID', 'StudentName']\n",
      "['1', 'Alice Johnson']\n",
      "['14', 'Ava Martinez']\n",
      "['16', 'Avery Harris']\n",
      "['2', 'Bob Smith']\n",
      "['22', 'Carter Brown']\n",
      "['3', 'Charlie Davis']\n",
      "['23', 'Chloe Wilson']\n",
      "['5', 'David Brown']\n",
      "['9', 'Ella Robinson']\n",
      "['4', 'Emma Wilson']\n",
      "['24', 'Ethan Moore']\n",
      "['17', 'Evelyn Wilson']\n",
      "['21', 'Grace Harris']\n",
      "['19', 'Harper Smith']\n",
      "['11', 'Isabella Taylor']\n",
      "['15', 'Jackson Turner']\n",
      "['8', 'Liam Harris']\n",
      "['20', 'Lincoln Davis']\n",
      "['18', 'Logan White']\n",
      "['13', 'Lucas Miller']\n",
      "['12', 'Mia Garcia']\n",
      "['10', 'Noah Lee']\n",
      "['6', 'Olivia Moore']\n",
      "['7', 'Sophia White']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/students_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "        print(formatted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BookID', 'AuthorID']\n",
      "['1', '1']\n",
      "['2', '2']\n",
      "['3', '3']\n",
      "['4', '4']\n",
      "['5', '5']\n",
      "['6', '6']\n",
      "['7', '7']\n",
      "['8', '8']\n",
      "['9', '9']\n",
      "['10', '10']\n",
      "['11', '11']\n",
      "['12', '12']\n",
      "['13', '13']\n",
      "['14', '14']\n",
      "['15', '15']\n",
      "['16', '16']\n",
      "['17', '17']\n",
      "['18', '18']\n",
      "['19', '19']\n",
      "['20', '20']\n",
      "['21', '21']\n",
      "['22', '22']\n",
      "['23', '23']\n",
      "['24', '24']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/bookauthors_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        formatted_line = '[' + ', '.join(\"'\" + element.strip(\"'\") + \"'\" for element in line) + ']'\n",
    "        print(formatted_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'BookID'\", \"'Title'\", \"'CategoryID'\"]\n",
      "[\"'1'\", \"'New Title'\", \"'1'\"]\n",
      "[\"'2'\", \"'To Kill a Mockingbird'\", \"'1'\"]\n",
      "[\"'3'\", \"'The Great Gatsby'\", \"'1'\"]\n",
      "[\"'4'\", \"'1984'\", \"'2'\"]\n",
      "[\"'5'\", \"'Brave New World'\", \"'2'\"]\n",
      "[\"'6'\", \"'Dune'\", \"'2'\"]\n",
      "[\"'7'\", \"'Pride and Prejudice'\", \"'3'\"]\n",
      "[\"'8'\", \"'Jane Eyre'\", \"'3'\"]\n",
      "[\"'9'\", \"'Wuthering Heights'\", \"'3'\"]\n",
      "[\"'10'\", \"'The Hobbit'\", \"'4'\"]\n",
      "[\"'11'\", \"'The Lord of the Rings'\", \"'4'\"]\n",
      "[\"'12'\", '\\'Harry Potter and the Sorcerer\"\\'s Stone\\'', \"'4'\"]\n",
      "[\"'13'\", \"'The Catcher in the Rye'\", \"'5'\"]\n",
      "[\"'14'\", \"'Fahrenheit 451'\", \"'5'\"]\n",
      "[\"'15'\", \"'The Odyssey'\", \"'6'\"]\n",
      "[\"'16'\", \"'The Iliad'\", \"'6'\"]\n",
      "[\"'17'\", \"'One Hundred Years of Solitude'\", \"'1'\"]\n",
      "[\"'18'\", \"'The Alchemist'\", \"'2'\"]\n",
      "[\"'19'\", \"'The Chronicles of Narnia'\", \"'4'\"]\n",
      "[\"'20'\", \"'The Shining'\", \"'5'\"]\n",
      "[\"'21'\", \"'Jurassic Park'\", \"'7'\"]\n",
      "[\"'22'\", \"'The Da Vinci Code'\", \"'8'\"]\n",
      "[\"'23'\", \"'The Girl with the Dragon Tattoo'\", \"'8'\"]\n",
      "[\"'24'\", \"'The Hunger Games'\", \"'9'\"]\n",
      "'Title'\n",
      "'The Hunger Games'\n",
      "'To Kill a Mockingbird'\n",
      "'New Title'\n",
      "'The Girl with the Dragon Tattoo'\n",
      "'The Great Gatsby'\n",
      "'The Shining'\n",
      "'The Chronicles of Narnia'\n",
      "'Jurassic Park'\n",
      "'The Hobbit'\n",
      "'One Hundred Years of Solitude'\n",
      "'The Iliad'\n",
      "'Dune'\n",
      "'The Alchemist'\n",
      "'Fahrenheit 451'\n",
      "'Pride and Prejudice'\n",
      "'The Da Vinci Code'\n",
      "'Brave New World'\n",
      "'The Lord of the Rings'\n",
      "'Wuthering Heights'\n",
      "'Jane Eyre'\n",
      "'The Catcher in the Rye'\n",
      "'1984'\n",
      "'Harry Potter and the Sorcerer\"'s Stone'\n",
      "'The Odyssey'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m display_all_books()\n\u001b[0;32m     69\u001b[0m display_all_authors()\n\u001b[1;32m---> 70\u001b[0m \u001b[43msearch_books_by_category\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mScience Fiction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m display_borrowed_books_by_student(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     72\u001b[0m calculate_total_books_by_category()\n",
      "Cell \u001b[1;32mIn[11], line 26\u001b[0m, in \u001b[0;36msearch_books_by_category\u001b[1;34m(category)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_books_by_category\u001b[39m(category):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m book \u001b[38;5;129;01min\u001b[39;00m books:\n\u001b[1;32m---> 26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbook\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m category:  \u001b[38;5;66;03m# Assuming category is the fourth column\u001b[39;00m\n\u001b[0;32m     27\u001b[0m             \u001b[38;5;28mprint\u001b[39m(book)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Load data from CSV file\n",
    "books = []\n",
    "with open('C:/Users/HUDA/OneDrive/Desktop/books_backup.csv', encoding=\"utf8\") as f:\n",
    "    csv_reader = csv.reader(f)\n",
    "    for line in csv_reader:\n",
    "        books.append(line)\n",
    "\n",
    "# 1. Display all books\n",
    "def display_all_books():\n",
    "    for book in books:\n",
    "        print(book)\n",
    "\n",
    "# 2. Display all authors\n",
    "def display_all_authors():\n",
    "    authors = set()\n",
    "    for book in books:\n",
    "        authors.add(book[1])  # Assuming author is the second column\n",
    "    for author in authors:\n",
    "        print(author)\n",
    "\n",
    "# 3. Search for books by category\n",
    "def search_books_by_category(category):\n",
    "    for book in books:\n",
    "        if book[3] == category:  # Assuming category is the fourth column\n",
    "            print(book)\n",
    "\n",
    "# 4. Display borrowed books by student\n",
    "def display_borrowed_books_by_student(student_id):\n",
    "    for book in books:\n",
    "        if book[4] == student_id:  # Assuming student ID is the fifth column\n",
    "            print(book)\n",
    "\n",
    "# 5. Calculate total number of books in each category\n",
    "def calculate_total_books_by_category():\n",
    "    category_totals = {}\n",
    "    for book in books:\n",
    "        category = book[3]  # Assuming category is the fourth column\n",
    "        category_totals[category] = category_totals.get(category, 0) + 1\n",
    "    for category, total_books in category_totals.items():\n",
    "        print(f\"{category}: {total_books}\")\n",
    "\n",
    "# 6. Display books by author\n",
    "def display_books_by_author(author_name):\n",
    "    for book in books:\n",
    "        if book[1] == author_name:  # Assuming author is the second column\n",
    "            print(book)\n",
    "\n",
    "# 7. Display all borrowed books\n",
    "def display_all_borrowed_books():\n",
    "    for book in books:\n",
    "        if book[5] != '0':  # Assuming if a book is borrowed, there's a non-zero value in the sixth column\n",
    "            print(book)\n",
    "\n",
    "# 8. Calculate late fees for borrowed books\n",
    "def calculate_late_fees():\n",
    "    # Your code to calculate late fees goes here\n",
    "    pass\n",
    "\n",
    "# 9. Search for books by title\n",
    "def search_books_by_title(title):\n",
    "    for book in books:\n",
    "        if title.lower() in book[0].lower():  # Assuming title is the first column\n",
    "            print(book)\n",
    "\n",
    "# Test the functions\n",
    "display_all_books()\n",
    "display_all_authors()\n",
    "search_books_by_category('Science Fiction')\n",
    "display_borrowed_books_by_student('1')\n",
    "calculate_total_books_by_category()\n",
    "display_books_by_author('J.K. Rowling')\n",
    "display_all_borrowed_books()\n",
    "calculate_late_fees()\n",
    "search_books_by_title('Harry Potter')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dict contains fields not in fieldnames: \"'AuthorID'\", \"'AuthorName'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m     csv_writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(f, fieldnames\u001b[38;5;241m=\u001b[39mfieldnames)\n\u001b[0;32m     36\u001b[0m     csv_writer\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mcsv_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerged CSV file created successfully at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output_file_path)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\csv.py:157\u001b[0m, in \u001b[0;36mDictWriter.writerows\u001b[1;34m(self, rowdicts)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterows\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdicts):\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowdicts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2032.0_x64__qbz5n2kfra8p0\\Lib\\csv.py:149\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[1;34m(self, rowdict)\u001b[0m\n\u001b[0;32m    147\u001b[0m     wrong_fields \u001b[38;5;241m=\u001b[39m rowdict\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[1;32m--> 149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict contains fields not in fieldnames: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    150\u001b[0m                          \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames)\n",
      "\u001b[1;31mValueError\u001b[0m: dict contains fields not in fieldnames: \"'AuthorID'\", \"'AuthorName'\""
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to load CSV data\n",
    "def load_csv_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, encoding=\"utf8\") as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "# List of file paths for all CSV files\n",
    "file_paths = [\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/books_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/authors_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/borrowedbooks_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/categories_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/students_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/bookauthors_backup.csv'\n",
    "    \n",
    "    # Add paths for all 6 CSV files here\n",
    "]\n",
    "\n",
    "# Load data from all CSV files into separate lists\n",
    "all_data = []\n",
    "for file_path in file_paths:\n",
    "    data = load_csv_data(file_path)\n",
    "    all_data.extend(data)  # Merge data from all files into one list\n",
    "\n",
    "# Write the merged data into a new CSV file\n",
    "output_file_path = 'C:/Users/HUDA/OneDrive/Desktop/merged_file.csv'\n",
    "with open(output_file_path, 'w', newline='', encoding=\"utf8\") as f:\n",
    "    fieldnames = all_data[0].keys()  # Assuming all files have the same structure\n",
    "    csv_writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(all_data)\n",
    "\n",
    "print(\"Merged CSV file created successfully at:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged CSV file created successfully at: C:/Users/HUDA/OneDrive/Desktop/merged_file.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Function to load CSV data\n",
    "def load_csv_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, encoding=\"utf8\") as f:\n",
    "        csv_reader = csv.DictReader(f)\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "# List of file paths for all CSV files\n",
    "file_paths = [\n",
    "     'C:/Users/HUDA/OneDrive/Desktop/books_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/authors_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/borrowedbooks_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/categories_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/students_backup.csv',\n",
    "    'C:/Users/HUDA/OneDrive/Desktop/bookauthors_backup.csv'\n",
    "    \n",
    "    # Add paths for all 6 CSV files here\n",
    "]\n",
    "\n",
    "# Load data from all CSV files into separate lists\n",
    "all_data = []\n",
    "for file_path in file_paths:\n",
    "    data = load_csv_data(file_path)\n",
    "    all_data.extend(data)  # Merge data from all files into one list\n",
    "\n",
    "# Get field names dynamically from the data\n",
    "fieldnames = []\n",
    "for row in all_data:\n",
    "    for key in row.keys():\n",
    "        if key not in fieldnames:\n",
    "            fieldnames.append(key)\n",
    "\n",
    "# Write the merged data into a new CSV file\n",
    "output_file_path = 'C:/Users/HUDA/OneDrive/Desktop/merged_file.csv'\n",
    "with open(output_file_path, 'w', newline='', encoding=\"utf8\") as f:\n",
    "    csv_writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    \n",
    "    csv_writer.writeheader()\n",
    "    csv_writer.writerows(all_data)\n",
    "\n",
    "print(\"Merged CSV file created successfully at:\", output_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
